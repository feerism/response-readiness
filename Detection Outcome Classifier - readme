# Detection Outcome Classifier — description

**Purpose**

* Standardize SOC decisions about alert outcomes using yes, no, skip inputs
* Separate real threat, prevented threat, benign but correctly detected, and noise
* Produce an explainable decision with next action guidance

**Supported outcomes**

* TP Malicious
* TP Benign
* TP Prevented
* False Positive
* False Negative
* True Negative
* Indeterminate

**Inputs asked to the analyst**

* Alert generated
* Cybersecurity impact present
* Malicious evidence in logs or artifacts
* Threat intelligence match
* Suspicious user or asset behavior
* Control failure
* Business impact
* Authorized or approved activity
* Expected activity for this user or system
* Red Team activity
* File quarantined or deleted by controls
* User executed or accessed the payload
* FP specific checks
  • Alert incorrectly indicated a vulnerability
  • Tool incorrectly classified benign content as malicious
  • Benign activity incorrectly classified as malicious

**Answer options**

* yes, no, skip
  skip records unknown and does not change scoring

**Core logic overview**

* If no alert
  • malicious later confirmed gives False Negative
  • no malicious gives True Negative
  • unknown gives Indeterminate
* If alert exists
  • Red Team and expected gives TP Benign
  • Malicious evidence present and control did not fail and no impact and file was quarantined or deleted and user did not execute gives TP Prevented
  • Malicious evidence present and not authorized gives TP Malicious
  • Malicious evidence present and authorized or expected or Red Team gives TP Benign
  • Any FP specific check confirmed gives False Positive
  • No evidence and not authorized and not expected and not Red Team gives False Positive
  • Otherwise Indeterminate

**Control failure weighting**

* When malicious evidence is present and control failure is yes
  risk score increases more to reflect higher threat
* When no malicious evidence and control failure is yes
  benign score increases to reflect tuning need rather than threat

**Scoring**

* Risk score range zero to thirteen
  sources include impact, malicious evidence, threat intelligence match, suspicious behavior, business impact, control failure in malicious context
* Benign context score range zero to five
  sources include authorized, expected, Red Team, control failure in benign context

**False Positive auto skip behavior**

* FP checks are asked in order
  if the first is yes the rest are skipped
  if the second is yes the third is skipped
  ensures a single clear FP reason

**Outputs**

* Classification
* Reason text that explains the rule path
* Recommended action for the SOC
* Risk score and benign context score

**Recommended actions by class**

* TP Malicious
  proceed with containment, eradication, recovery, and lessons learned
* TP Prevented
  document prevention success, validate rules, keep controls as is
* TP Benign
  document approved or expected activity, consider tuning to reduce noise
* False Positive
  refine rule logic, thresholds, signatures, or context enrichment
* False Negative
  improve coverage, write or adjust detections, add telemetry
* True Negative
  no action
* Indeterminate
  gather missing logs, approvals, and intelligence

**Intended use**

* Run during alert triage and post incident review
* Works as a terminal script or can be embedded in analyst forms
* Optional CSV logging can record timestamp, answers, scores, and outcome for trend reporting

If you want, I can add a one page PDF version or a CSV logging option description.
